Key-value stores
Intro
  Key-value stores are distributed hash tables
  Key generated by hash should be unique
  Key assumes nothing about value
    Can be blob, image, server name, etc
    Prefer to keep value size ~small (KB to MB)
    Put large data in blob store
    Put link to blob in value field
  Great for storing user sessions
  Building NoSQL databases
  Scaling trad databases hard to scale
    with high consistency and availability
    in a distributed environment
  Primary-key datastore used by
    Amazon
    Facebook
    Instagram
    Netflix
    many more
    instead of traditional online transaction processing databases (OLTP)
  Key-value usage
    Bestseller lists
    Shopping carts
    Customer preferences
    Session management
    Sales rank
    Product catalogs
  Many apps do not require traditional RDBMS
    Often expensive in cost and performance

Designing key-value store & API
  Key requirements to overcome traditional databases
    Configurable services
      Some apps trade strong consistency for higher availability
      Some won't
      Need tight control over tradeoffs
        Cost effectivess, performance too
    Ability to always write
      Must always be able to write in
      Strong consistency not always fulfilled - CAP theorem
    Hardware heterogeneity
      Should not have distinguished nodes
      Every node should be able to do every task
      Servers can be heterogenous, new nodes may be more capable
  Non-functional requirements
    Scalable
      Run on 10ks servers around globe
      Incremental scalability highly desirable
      Add or remove as needed, minimal/no disruption
      Handle enormous number of users
    Available
      Provide continuous service
      Strong consistency tradeoff
    Fault tolerance
      Operate uninterrupted despite server/component failure
  Always run on multiple servers
    Single can't meet requirements after a specific point
    Failure of mega-server = downtime
  Assumptions
    Data centers hosting are trusted, non-hostile
    Authentication and authorization already complete
    Requests and responses relayed over HTTPS
  API design
    Two primary functions: get and put
    get(key)
      Return value on basis of param key
      When data replicated, locate with specific key
        Done by system is weaker consistency model
        May even be >1 value returned against key
    put(key, value)
      Store value assoc with key
      System automatically determines where to place
      May keep metadata about stored object, e.g. version number
    Keep hashes of value for data integrity checks
      May take before or after encryption/compression
      Depends on specific applicatoin
      But need to do it consistently for get/put
    Data type
      Key is often primary key
      Value any arbitrary binary data
        Dynamo uses MD5 hashes to generate 128-bit ID
        Determine which server responsible for key
  All future based on DynamoDB

Ensure scalability and replication
  Scalability
    Store key-value data in storage nodes
    May need to add or remove depending on demand
    Partition data to distribute across nodes
    Ex. have 4 nodes, 25% of requests to each node
      Trad. solve through modulus operator
      Hash request ID, find remainder, value is node number
    Problem
      Add/remove node = move a lot of keys
      Very inefficient
        Costly, high latency
    Consistent hashing
      Conceptual ring of hashes from 0 to n - 1
      n is number of available hash values
      Use node id, calculate hash, map to ring
      Apply same process to requests
      Each request completed by next node found moving clockwise
      Add new node?
        Next node affected, share data with newly added node
        Other nodes unaffected
        Easy to scale, changes to nodes minimal
        Only small pecent of keys need to move
      Hashes randomly distributed
        Requests should be distributed evenly on average
      Downside, load not equally divided in practice
        Can result in hotspots
        How to solve?
        Use virtual nodes
      Virtual nodes
        Apply multiple hash functions to same key
        Wind up with multiple locations on ring
        More powerful server? Give more hash functions, more locs on ring
        If node fails, workload distributed over other nodes
        Each node can decide how many virtual nodes responsible for
    Now scalable
  Availability
    Primary-secondary or peer-to-peer
    Primary-secondary does not fulfill need to always write
      Primary can get overloaded
      If primary fails, availability lost while upgrading secondary
    Peer-to-peer
      All storage areas are primary
      Usually inefficient and costly to replicate in all n nodes
      Often 3-5 storage nodes replicated
      So replicate to 3-5 nodes (n)
        Controlled by node coordinator
        List of successors = "preference lists"
          Coord hits n - 1 successors
        Don't replicate on same physical nodes
          Skip virtual nodes whose physical node already on list
  CAP theorem
    Key-value stores can be either consistent or available when partition
    Prefer availability over consistency
    Eventually sync up
    Need a way to handle conflicts though, using data versioning

Versioning data
  When partitions and node failures happen
  Object version history may become fragmented
  System needs to accept potentially several copies of same data
  Need to maintain causality between events
    Can use timestamps
      However time is not reliable in distributed system
    Vector clocks
      List of (node, counter) pairs
      Single vector clock for every version of an object
        If different vector clocks, tell if causally related
        More in a bit
    API design modification
      Need info about which node performed, vector clock value
      get(key)
        Return object OR
        Return collection of conflicting objects with context
          context = metadata incl. version
      put(key, context, value)
        Find node where value should be placed based on key
        If conflict, ask client to resolve
        To update, client must vie context
        Determine version using vector clock by supplying context
        If key-value store has access to several branches
          Provide all objects at leaf nodes & version info in context
        Reconcile disparate versions & merge = update
          Comparable to how Git works
            Automatic if possible
            Up to manual resolve if auto not possible
  Vector clock example
    Write request
    Node A handles first version E1
      Vector clock has node & counter - [A, 1]
    Node A handles another write E2
      VC: [A, 2]
    Network partition
      Request handled by nodes B & C
    E3: ([A, 2], [B, 1])
    E4: ([A, 2], [C, 1])
    Network partition repaired
      Conflicts
      Context: ([A, 3], [B, 1], [C, 1])
    Reconciliation
    E5: [A, 4]
  Vector clock limitations
    Size may increase if multiple servers write to same object simultatneously
      Unlikely in practice
      Writes typically handled by top n nodes in pref list
      But if not, can wind up with:
        ([A,10], [B,4], [C,1], [D,2], [E,1], [F,3], [G,5], [H,7], [I,2], [J,2], [K,1], [L,1])
      Hassle to store and maintain!
    Limit size of vector clock
      Clock truncation stratgetgy
      Store timestamp with each (node, counter)
      Show when data item last updated by node
      Purged past threshold length (say 10)
        Descendant linkages no longer precisely calculable
      Can lead to lack of efficiency in reconciliation
  get and put operations
    System should be configurable
    Control tradeoffs: availability, consistency, performance, cost
    Every node can handle get/put (read/writes)
    Node = "coordinator"
    Coord = first among top n nodes in prefernce list
    How does client select node?
      1. Route request to generic load balancer
        Client not linked to code
      2. Use partition-aware client library
        Route requests directly to appropriate nodes
        Lower latency achieved, less hops
    Configurable
      Consistency protocol similar to quorum systems
    Quorum example
      n = 3
      Three copies of data to be maintained
      Nodes in ring
        ABCDE clockwise order
      Write on A, copies on B & C
      r = number of nodes for successful read
      w = number of nodes for successful write
        make sure of it - data async in remaining
      If r = 2, read from 2 nodes
      Pick r + w so one node in common
      Ensures latest written value
      r + w > n
      Options
        r = 1, w = 2 - violates constraints
          could read from async node - JM
        r = 2, w = 2 - allowed
          guaranteed to read from at least one sync
        r = 3, w = 1 - fast writes, slow reads
          only one write async, need to visit all n
        r = 1, w = 3 - fast reads, slow writes
          all writes sync, only need to read from one
    In quorum model
      Latency of get determined by slowest r
      Larger r = available up, consistency down
      Coordinator produces vector clock and writes new version locally on put()
        Sends n highest ranking nods with updated version and new vector clock
          Write successful if w - 1 nodes respond
            Coord writes self first, so w writes in total
      Requests for get main to n highest-ranked nodes in preference list
        Wait for r answers before returning results
        Coords return all dataset version if get several from same source
          Divergent histories
          Merge, key value override previous versions
    Fulfills scalable, available, conflict-resolution, configurable
    Now fault tolerance

Fault tolerance and failure detection
  Quorum based approach to handling faliures
    Minimum number of votes for distributed transaction to proceed
    If server is part of consensus and down, can't perform
      Availability, durability down
  Sloppy quorum, not strict quorum
  Strict quorum
    Leader manages consensus comms
    Participants ack after write
    Leader responds to client
    But if leader down?
    Participants declare dead, must elect new leader
    Negative impact on performance if frequent
      More election time than work time
  Sloppy quorum
    First n healthy nodes from pref list handle all read/write
    May not always be first n nodes discovered in ring
    Say a node is down
    Go to next node in pref list (D)
      Nodes writes, with a note to self should have been A
      When A is back up, D sends request to A
      When A updates, D removes item from local storage
      "Hinted handoff"
      Ensure reads & writes fulfilled if temp failure
  Also key to ensure replication across data centers
    Power outages, cooling failures, network failures, natural disasters
  Limitations of hinted handoff
    What if hinted replicat unavailable before restoring to originated replica?
    Best in system with minimal membership churn and node failures
  Permanent failures
    Keep replicas synched for durability
    Speed up detection of inconsistencies, reduce quantity of transferred data
    Merkle trees
  Merkle tree
    Values of individual keys hashed and used as leaves of tree
    Hashes of children in parent nodes higher up tree
      Effectively merged data up tree - JM
    Verify each branch independently
      Do not need to download entire tree/dataset
        Effectively compare roots, go down divergent branches - JM
    No need for synch if roots, leaves same
      Identify keys out of synch when nodes exchange child hash values
      Bubble up tree when key value changes - JM
    Mechanism for anti-entropy
  Anti-entropy with Merkle trees
    Each node keeps a distinct Merkle tree for range of keys hosts for each virtual node
    Determine if keys in given range are correct
    Root of Merkle tree corresponding to common key ranges exchanged
    Do not proceed if roots same
    Traverse left and right children using recursion
      Identify where differences
      Perform necessary synch
    Advantage
      Examine branch of tree without downloading tree or complete dataset
      Reduce quantity of data for synch & number of disc accesses
    Disadvantage
      Must recalculate tree hash whenever (virtual) nodes joins or departs
        Multiple key ranges are affected
  Nodes in ring detect failure of other nodes
    Don't change when node goes down
      Rarely permanent
      Be very careful about addition and removal
    Planned commission/decommission recorded peristently
      All nodes keep on storage
      Reconcile among ring members with gossip protocol
    Gossip-based protocol
      Eventually consistent view of membership
      Ex.
        A makes a change, comms to B & E
        D makes a change, comms to C & E
        Every node knows about each other
        Asynch info sharing
        Takes little bandwidth
      Can it fail
        What if virtual node N1 of A wants to be added
        Ask N2, also virtual node of A
        Both consider part of same ring
        Will update themselves after change
        "Logical partitioning"
      Preventing logical partitioning
        Make a few nodes play the roles of seeds
        Define via configuration service
        Known to all working nodes
        Eventually reconcile membership with seed